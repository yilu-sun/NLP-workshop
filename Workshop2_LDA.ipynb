{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec04c21b-48e8-491a-abab-a1a1522f987a",
   "metadata": {},
   "source": [
    "### NLP Workshop Part 2\n",
    "\n",
    "#### Topic Modeling via LDA:\n",
    "- Topic modelling in natural language processing is a technique which assigns topic to a given corpus based on the words present. Topic modelling is important, because in this world full of data it has become increasingly important to categories the documents.\n",
    "- Clustering the transcriptions of the conversation turns in a dialogue in an unsupervised fashion helps us to understand the topics of the conversation quickly. \n",
    "  - **Ideas**:\n",
    "    - LDA\n",
    "    - Unsupervised transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdfe50-989e-433c-9b2b-d1c1f59310b6",
   "metadata": {},
   "source": [
    "### Code Demo: Unsupervised mechanisms to group corpuses into concepts/clusters\n",
    "\n",
    "- LDA [What is it?](https://medium.com/analytics-vidhya/topic-modelling-using-lda-aa11ec9bec13)  |  [Link to package](https://radimrehurek.com/gensim/models/ldamodel.html)  |  [MultiCore Fast LDA](https://radimrehurek.com/gensim/models/ldamulticore.html)\n",
    "- Unsupervised transformers [What is it?](https://jalammar.github.io/illustrated-transformer/)  |  [Hugging Face](https://huggingface.co/docs/transformers/index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7905ea7-ef9d-4286-8571-30a1e7e0ecf0",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91829bf-d502-4ba5-b68b-fd13c5b2cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0ebd8-f3d3-4aba-8f2c-cfd5ad3578b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801a2e5-a250-4d74-b918-88b37d6236f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be7378-d98b-4d33-9b08-3a7782a36caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_file = pd.read_csv('Transcription_E04.csv') # can swap for a different data file \n",
    "transcription_file = transcription_file[transcription_file['prompt_id']=='7c9053bd-3d78-4dc4-8canb-74947po3bdf0']\n",
    "\n",
    "response_list = []\n",
    "\n",
    "for doc in transcription_file.text_response:\n",
    "    response_list.append(preprocess(doc))\n",
    "\n",
    "print(response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfc233-23ce-43cb-a7ec-efa07ab6d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dictionary\n",
    "id2word = Dictionary(response_list)\n",
    "\n",
    "# set up the corpus \n",
    "corpus = [id2word.doc2bow(text) for text in response_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827aeb7-84e6-4af3-9d7c-dd695155a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check corpus data\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb74321-b1b2-4ead-8b5d-053d1caaf0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dictionary + corpus output\n",
    "[[(id2word[i], freq) for i, freq in doc] for doc in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6456b-5c07-46c2-b10c-62cae3dee279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model \n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=2, # can change the number of topics \n",
    "                   random_state=100,\n",
    "                   update_every=1,\n",
    "                   chunksize=100,\n",
    "                   alpha='auto',\n",
    "                   per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbdf8c-e0c8-4aa6-8d8b-a95c3cb0efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out and check the two topics \n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa730c16-2128-4ad4-ba03-3bd5c56e7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the topics \n",
    "pyLDAvis.enable_notebook()\n",
    "gensimvis.prepare(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52602984-1ad7-4544-b339-3e963fc70961",
   "metadata": {},
   "source": [
    "## Team Discussion:\n",
    "1. What are your findings? \n",
    "2. What are the pros and cons of this approach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedee58-6434-438a-8de6-d8ab1bb771f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a pre-defined testing dataset\n",
    "processed_X_train = []\n",
    "processed_X_test = []\n",
    "\n",
    "for doc in X_train:\n",
    "    processed_X_train.append(preprocess(doc))\n",
    "\n",
    "for doc in X_test:\n",
    "    processed_X_test.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38bef7-b252-48ff-8503-4ebb0bd6b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the data \n",
    "for doc in X_train:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49108ed6-01a0-4487-aedc-58dc050da15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b00964-80f9-4c92-af7d-e082429b9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, y_train_names = newsgroups_train['data'], newsgroups_train['target'], newsgroups_train['target_names'] \n",
    "X_test, y_test, y_test_names = newsgroups_test['data'], newsgroups_test['target'], newsgroups_test['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d577c8-bab0-4a49-83b5-7f5619975c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dictionary from 'processed_docs' containing the number of times a word appears \n",
    "in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
    "'''\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db93a9-ba95-4716-a889-e9b220df2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526b648-7960-4e86-a5d0-ce47cb9705d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checking dictionary created\n",
    "'''\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b5bf5-766a-4081-bf2a-3023eb2e43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to 'bow_corpus'\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dc94c-1297-4ec6-be25-3fd2e4f58db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_X_train[0])\n",
    "for k, v in bow_corpus[0]:\n",
    "    print(dictionary[k], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525471df-56e9-4be0-9bab-00c6a6b502ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters can be tweaked based on the understanding of the data.\n",
    "\n",
    "# For instance, the number of topics can be set to what we expect the data to divide into.\n",
    "# Passes can be experimented with based on the data.\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106209e-e837-4b34-a256-aaae6abf1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display learned topics\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# LDA outputs the topics it leared from the data. For each topic, it shows the words and their corresponding\n",
    "# importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a81a0-f370-4d7d-b2b2-1ac4d46f9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiztion\n",
    "pyLDAvis.enable_notebook()\n",
    "gensimvis.prepare(lda_model, bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e8f1c-59b0-426d-bf38-bebf6e5f95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA inference on test document\n",
    "\n",
    "num = 100 #10\n",
    "doc = processed_X_test[num]\n",
    "# Data preprocessing step for the unseen document\n",
    "bow_vector = dictionary.doc2bow(doc)\n",
    "\n",
    "print(\"Original doc----->\\n\")\n",
    "print(X_test[num])\n",
    "\n",
    "print(\"Topic inferred by LDA----->\\n\")\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a75e3-f059-4e1e-9871-963155a20206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing LDA model on new corpus of data.\n",
    "\n",
    "lda_model.update(other_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
